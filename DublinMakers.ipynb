{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31df3b4e-c104-4d9a-aa86-151b866a316f",
   "metadata": {},
   "source": [
    "# Digital Mirror\n",
    "\n",
    "### John S Butler and Cian McLoughlin\n",
    "\n",
    "The __Digital Mirror__ is a collaboration between artist Cian McLoughlin and mathematician and neuroscientist John Butler of TU Dublin. Together, they explore the connections between art, machine learning, and neuroscience in the context of facial recognition.\n",
    "\n",
    "This code creates the eigenfaces from a video recording by:\n",
    "1. A 10 second video at 30 frames a second giving 300 images that are 640x480. \n",
    "2. These images are averaged to get the \"meanface\".\n",
    "3. The \"meanface\" is subtracted from each image, Convert each subtracted image from a 2D matrix 640x480 to a vector 1x307200. Make a matrix from all the subtraced images which is 300x307200 \n",
    "4. Calculate then eigenvalues and eigenvectors of subtracted images using the Principal Component Analysis (PCA)\n",
    "5. Plot the Eigenfaces\n",
    "6. Reconstruct an Image\n",
    "7. How many eigenfaces do we need?\n",
    "8. Comparison of Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a4d47-69e9-4255-829e-b960be7c3fb1",
   "metadata": {},
   "source": [
    "## LIBRARIES NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01c677-2cc8-4cb4-869f-64aa273b2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Computer vision tasks\n",
    "import matplotlib.pyplot as plt  # Plotting and visualization\n",
    "import os  # Interacting with the operating system (file/directory management)\n",
    "import numpy as np  # Numerical computing (arrays, matrices)\n",
    "from sklearn.decomposition import PCA  # Dimensionality reduction (PCA)\n",
    "import time  # Time-related functions (e.g., sleep, execution time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619af53-b3a7-43c0-be5a-9bc0f224af25",
   "metadata": {},
   "source": [
    "## IMAGE RECORDING AND PLOTTING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d8da4-419c-49fa-83a6-f44fdc3bb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the folder where the files will be stored\n",
    "name = \"Test\"\n",
    "\n",
    "# Record the start time for measuring how long the script takes to run\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify the directory name by concatenating the base directory with the specified name\n",
    "# In this case, it's creating a path like \"EigenFace/Test\"\n",
    "directory_name = \"EigenFace/\" + name\n",
    "\n",
    "# Check if the directory already exists and if it is a directory (not a file with the same name)\n",
    "if os.path.exists(directory_name) and os.path.isdir(directory_name):\n",
    "    # If the directory exists, print a confirmation message\n",
    "    print(f\"The directory '{directory_name}' exists.\")\n",
    "else:\n",
    "    # If the directory does not exist, create it using os.mkdir\n",
    "    os.mkdir(directory_name)\n",
    "    # Print a success message indicating the directory was created\n",
    "    print(f\"Directory '{directory_name}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8e3c4-9d69-4f5a-8f59-378ba10d659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMAGE RECORDING AND PLOTTING FUNCTIONS\n",
    "\n",
    "### VIDEO RECORDING \n",
    "def record_video(output_path, frame_width=640, frame_height=480, fps=30, duration=10):\n",
    "    \"\"\"\n",
    "    Records a video using the default camera and saves grayscale frames as images.\n",
    "\n",
    "    Parameters:\n",
    "    output_path (str): The path to save the output video.\n",
    "    frame_width (int): Width of the video frame.\n",
    "    frame_height (int): Height of the video frame.\n",
    "    fps (int): Frames per second.\n",
    "    duration (int): Duration of the video in seconds.\n",
    "\n",
    "    Returns:\n",
    "    images (list): List of grayscale images captured from the video.\n",
    "    \"\"\"\n",
    " \n",
    "    # Open the default camera (usually the first camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # List of facial expressions to show on the screen during recording\n",
    "    FACES = [\"Happy\", \"Angry\", \"Confused\", \"Puppy Dog\", \"Weirded Out\", \n",
    "             \"Blank\", \"Delighted\", \"Sick\", \"Shocked\", \"Sad\", \"Happy Again\"]\n",
    "    # Set the width and height of the frames to be captured\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # For MP4 output\n",
    "    output_video=\"EigenFace/\"+output_path+\"/\"+output_path+\".mp4\"\n",
    "    # Uncomment the following line to save video\n",
    "    # out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "    face_count=0\n",
    "    \n",
    "    # Calculate the number of frames to capture based on the duration and fps\n",
    "    num_frames_to_capture = int(duration * fps)\n",
    "    frame_count = 0\n",
    "    images=[]\n",
    "    while frame_count < num_frames_to_capture:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Uncomment to write the frame to the output file\n",
    "        #   out.write(frame)\n",
    "        \n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('Look at the camera and move your head', frame)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        images.append(gray_frame)\n",
    "        # Save the grayscale frame as an image\n",
    "        frame_filename = os.path.join('output_images_folder', f'frame_{frame_count:04d}.png')\n",
    "#        cv2.imwrite(frame_filename, gray_frame)\n",
    "        # Display the frame (optional)\n",
    "        if frame_count%np.round(num_frames_to_capture/10)==0:\n",
    "            face_count=face_count+1\n",
    "            \n",
    "        cv2.imshow(f\"Make a {FACES[face_count]} face\", frame)\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "    # Release the camera and file writer\n",
    "    cap.release()\n",
    "    # Uncomment the following line to save video\n",
    "    # out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.waitKey(1)\n",
    "    print(f\"Images recorded \")\n",
    "    return images\n",
    "\n",
    "\n",
    "# Function to plot the mean face and eigenfaces\n",
    "def plot_gallery(images, titles, h, w,name, n_row=1, n_col=6):\n",
    "    \"\"\"\n",
    "    Plots a gallery of images (e.g., mean face and eigenfaces).\n",
    "\n",
    "    Parameters:\n",
    "    images (list): List of images to display.\n",
    "    titles (list): Titles for each subplot.\n",
    "    h (int): Image height.\n",
    "    w (int): Image width.\n",
    "    name (str): Name for the output file.\n",
    "    n_row (int): Number of rows in the plot.\n",
    "    n_col (int): Number of columns in the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        \n",
    "    eigen_filename=name+\"eigenfaces.png\"\n",
    "    eigen_filename=\"EigenFace/\"+name+\"/\"+eigen_filename\n",
    "    plt.suptitle(\"The Digital Mirror: AI and the Evolution of Portraiture\",fontsize=24)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(eigen_filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot the mean face and eigenfaces with titlte\n",
    "def plot_gallery_print(images, titles, h, w,name, n_row=1, n_col=3):\n",
    "    \"\"\"\n",
    "    Plots a gallery of images for printing purposes.\n",
    "\n",
    "    Parameters:\n",
    "    images (list): List of images to display.\n",
    "    titles (list): Titles for each subplot.\n",
    "    h (int): Image height.\n",
    "    w (int): Image width.\n",
    "    name (str): Name for the output file.\n",
    "    n_row (int): Number of rows in the plot.\n",
    "    n_col (int): Number of columns in the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(1.8 *2* n_col, 2.4*2 * n_row),)\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i], cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.suptitle(\"The Digital Mirror: AI and the Evolution of Portraiture\",fontsize=24)\n",
    "    file_name=\"EigenFace/\"+name+\"/\"+name+\".png\"    \n",
    "    plt.savefig(file_name, dpi=300)\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### FUNCTION TO COMPARE TWO FACES USING PCA\n",
    "def compare_faces(face1, face2):\n",
    "    \"\"\"\n",
    "    Compares two faces using PCA by calculating the Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    face1 (ndarray): First face image data.\n",
    "    face2 (ndarray): Second face image data.\n",
    "\n",
    "    Returns:\n",
    "    distance (float): Euclidean distance between the two faces in PCA space.\n",
    "    \"\"\"\n",
    "    # Transform faces to PCA space\n",
    "    face1_pca = pca.transform([face1])\n",
    "    face2_pca = pca.transform([face2])\n",
    "    \n",
    "    # Compute the Euclidean distance between the two faces\n",
    "    distance = np.linalg.norm(face1_pca - face2_pca)\n",
    "    print(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b5db8-1fee-4e48-b223-18e1def46f5e",
   "metadata": {},
   "source": [
    "## 1. Video Recording \n",
    "\n",
    "The camera will record for 10 seconds. Look at the video and follow the instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef706d-e137-4028-8f6d-fb3f910ab48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "images=record_video(name, duration=10)  # Record for 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111dabb-6c65-4f40-8b83-165ac4fa8192",
   "metadata": {},
   "source": [
    "## EIGENFACES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7c573-7eda-46ab-8984-633b576f3b72",
   "metadata": {},
   "source": [
    "## 2. Meanface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37f37f-9a9a-4a82-892a-549e4850f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of images to a NumPy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Extract the number of samples, and the height (h) and width (w) of each image\n",
    "n_samples, h, w = images.shape\n",
    "\n",
    "# Reshape the images into a 2D data matrix where each row is a flattened image\n",
    "# The shape of X will be (n_samples, h * w), making it suitable for PCA\n",
    "X = np.reshape(images, (n_samples, h * w))\n",
    "\n",
    "# Determine the number of features (pixels per image) in the dataset\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Normalize the dataset by computing the mean of each feature (pixel) across all images\n",
    "# This step helps to standardize the data for PCA\n",
    "X_mean = X.mean(axis=0)\n",
    "\n",
    "# Compute the mean face by reshaping the mean vector back to the original image dimensions\n",
    "# This shows the average appearance of all the images in the dataset\n",
    "mean_face = X_mean.reshape((h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2207b5-a202-4c08-b040-f0bbfdb0beb2",
   "metadata": {},
   "source": [
    "## 3. Subtracted Meanface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd928f-65c1-4bf5-bea2-3b6c95005190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the dataset by subtracting the mean image from each image\n",
    "# This creates a dataset where the mean of each feature (pixel) is zero\n",
    "X_centered = X - X_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3827f6-a9f4-44e3-a29a-c908f41afc2c",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c65f0-af28-4c2f-8030-a341be43217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Principal Component Analysis (PCA) to find the main modes of variation (eigenfaces)\n",
    "# n_components: Number of principal components (eigenfaces) to compute\n",
    "# svd_solver='randomized': A faster algorithm for large datasets\n",
    "# whiten=True: Normalize the principal components (useful for subsequent learning tasks)\n",
    "n_components = 200  # Number of eigenfaces to retain for dimensionality reduction\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(X_centered)\n",
    "\n",
    "# Extract the principal components (eigenfaces) from the PCA model\n",
    "# Each component is reshaped back to the original image dimensions (h, w)\n",
    "# The eigenfaces capture the most significant variations among the dataset images\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80228af5-f53f-421c-b906-c8b857ca2073",
   "metadata": {},
   "source": [
    "## 5. Plot the Eigenfaces\n",
    "### Example Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98721517-4e8d-4ff4-87d8-4a33b84fcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Titles for the eigenfaces\n",
    "eigenface_titles = [f\"Eigenface {i + 1}\" for i in range(eigenfaces.shape[0])]\n",
    "# Plot the mean face and the first 18 eigenfaces\n",
    "plot_gallery(np.vstack((mean_face[np.newaxis], eigenfaces[0:44:10])), [\"Meanface\"] + eigenface_titles[0:44:10], h, w,name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93d65a-5942-45af-8f45-7371b8e0c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the mean face and the first 18 eigenfaces\n",
    "plot_gallery_print(np.vstack((mean_face[np.newaxis], eigenfaces[[0,30]])), [\"Meanface\"] + eigenface_titles[0:34:28], h, w,name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647aae5-a156-464c-9eb1-db832da2511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(np.vstack((mean_face[np.newaxis], eigenfaces[0:23])), [\"Meanface\"] + eigenface_titles[0:23], h, w,name,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1af10-11f1-4170-8fec-7cea83ab107c",
   "metadata": {},
   "source": [
    "## 6. Reconstruct an Image\n",
    "The reconstruction allows us to see how well the reduced representation captures the original face information. If the reconstruction is close to the original, it indicates that the most important features have been retained. This also helps in assessing the effectiveness of the PCA dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ced245-2276-49f5-ad49-e5042e409ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Projecting faces onto the eigenface space\n",
    "# The PCA transform method is used to project the centered face data onto the eigenface space.\n",
    "# X_pca will contain the coordinates of the original images in the reduced dimensionality space (eigenface space).\n",
    "# This reduces the data to a lower-dimensional representation, keeping only the most significant features.\n",
    "X_pca = pca.transform(X_centered)\n",
    "\n",
    "# Reconstruct some faces from their projection in the eigenface space\n",
    "# The inverse_transform method projects the data back to the original space from the eigenface space.\n",
    "# X_reconstructed contains the reconstructed images, which approximate the original images using only the selected principal components.\n",
    "X_reconstructed = pca.inverse_transform(X_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa31da5-ad74-457c-8def-4ad89d79e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), subplot_kw={'xticks':[], 'yticks':[]})\n",
    "ax[0].imshow(X[100].reshape((h, w)), cmap='gray')\n",
    "ax[0].set_title(\"Original Face\")\n",
    "ax[1].imshow(X_reconstructed[100].reshape((h, w)), cmap='gray')\n",
    "ax[1].set_title(\"Digital Mirror: Reconstructed Face\")\n",
    "Recon_name=\"EigenFace/\"+name+\"/\"+name+\"_Recon.png\"\n",
    "plt.suptitle(\"The Digital Mirror: AI and the Evolution of Portraiture\",fontsize=24)\n",
    "plt.tight_layout() \n",
    "fig.savefig(Recon_name, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204256ae-1e7b-431a-850a-819df511077a",
   "metadata": {},
   "source": [
    "## 7. Variance Explained \n",
    "\n",
    "This code provides a graphical representation of how much variance each principal component (eigenface) explains in the dataset. By plotting the explained variance ratio, we can determine the significance of each eigenface and decide how many components to retain based on their contribution to the total variance. The horizontal line at 1% helps identify components that contribute minimally, guiding the decision to discard them for noise reduction or feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a0763-7b42-46f2-bb1b-7eeaf5310d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the explained variance ratio for each principal component (eigenface)\n",
    "# The explained_variance_ratio_ attribute of the PCA object shows the proportion of the dataset's\n",
    "# variance that each principal component accounts for.\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Plot the explained variance ratio to visualize how much information each eigenface captures\n",
    "plt.plot(explained_variance_ratio, 'k.:')  # 'k.:' specifies black dots connected by dotted lines\n",
    "\n",
    "# Label the x-axis as 'Eigenface Number', representing each principal component\n",
    "plt.xlabel(\"Eigenface Number\")\n",
    "\n",
    "# Label the y-axis as 'Information Explained', representing the amount of variance each eigenface explains\n",
    "plt.ylabel(\"Information Explained\")\n",
    "\n",
    "# Add a horizontal dashed line at the 1% threshold to highlight components explaining less than 1% variance\n",
    "# This line helps to identify the cutoff point for eigenfaces that contribute minimally to the dataset's information\n",
    "plt.hlines(0.01, 0, len(np.cumsum(explained_variance_ratio)), color='r', linestyles='dashed', label=\"1%\")\n",
    "\n",
    "# Display the legend to show labels for plot elements, such as the 1% threshold line\n",
    "plt.legend()\n",
    "# Set the title of the plot to describe its purpose\n",
    "plt.title(\"Information of each Eigenface\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa94bb-5bdf-4e6e-b0e9-be7eb2cf2ff0",
   "metadata": {},
   "source": [
    "This code shows how much of the dataset's variance is explained as more principal components (eigenfaces) are included. The plot helps visualize the cumulative explained variance, providing insight into how many eigenfaces are needed to retain a desired level of information. The horizontal lines at 80%, 95%, and 99% serve as benchmarks for deciding the number of components to use, which can be crucial for optimizing the trade-off between dimensionality reduction and information retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b6414-052e-47c1-b7f3-1ea2efc81c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance of the eigenfaces\n",
    "# np.arange(len(np.cumsum(explained_variance_ratio))) + 1 generates an array [1, 2, 3, ..., n]\n",
    "# np.cumsum(explained_variance_ratio) computes the cumulative sum of the explained variance ratios\n",
    "# 'k.:' specifies black dots connected by dotted lines\n",
    "plt.plot(np.arange(len(np.cumsum(explained_variance_ratio))) + 1, np.cumsum(explained_variance_ratio), 'k.:')\n",
    "\n",
    "# Label the x-axis as 'Number of Eigenfaces', indicating how many principal components are included\n",
    "plt.xlabel(\"Number of Eigenfaces\")\n",
    "\n",
    "# Label the y-axis as 'Percent of Faces Explained', showing the cumulative proportion of variance explained\n",
    "plt.ylabel(\"Percent of Faces Explained\")\n",
    "\n",
    "# Add horizontal dashed lines at specific thresholds to visualize when the cumulative variance reaches\n",
    "# significant proportions (80%, 95%, and 99%)\n",
    "# These lines help to decide the number of eigenfaces to retain for sufficient information capture\n",
    "plt.hlines(0.80, 0, len(np.cumsum(explained_variance_ratio)), color='g', linestyles='dashed', label=\"80%\")\n",
    "plt.hlines(0.95, 0, len(np.cumsum(explained_variance_ratio)), color='b', linestyles='dashed', label=\"95%\")\n",
    "plt.hlines(0.99, 0, len(np.cumsum(explained_variance_ratio)), color='r', linestyles='dashed', label=\"99%\")\n",
    "\n",
    "# Set the limits of the y-axis to ensure the plot ranges from 0 to 1 (0% to 100%)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Display the legend in the lower right corner to label the threshold lines\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Set the title of the plot to describe its purpose\n",
    "plt.title(\"Information of the Eigenfaces added together\")\n",
    "\n",
    "# Display the plot to visualize the cumulative explained variance\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4737a3-b7ce-4cd1-8b36-44374834854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4be7c-a2e6-4f9f-ab50-fc771df2a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8b3145-881e-4c05-96cb-20588b27bf06",
   "metadata": {},
   "source": [
    "## 8.  Who Do You Looklike?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5685470-02d1-49b7-9434-a9cc862a7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "John = cv2.imread(\"Comparison/John.png\")\n",
    "John=cv2.cvtColor(John, cv2.COLOR_BGR2GRAY)\n",
    "John = np.reshape(John,(h*w))\n",
    "compare_faces(John, X[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c27a91-2972-4d16-b27d-359531576e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "john_pca = pca.transform([John])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa8e91-6e9d-463f-bd89-c4780028c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_pca[2,:],X_pca[3,:],'k.-')\n",
    "plt.plot(X_pca[2,:].mean(),X_pca[3,:].mean(),'ko', label=name)\n",
    "plt.plot(john_pca[0,2],john_pca[0,3],'ro', label='John')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
